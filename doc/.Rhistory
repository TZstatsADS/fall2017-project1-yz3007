library("rvest")
library("tibble")
library("qdap")   # a lot of utility for text mining
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
source("../lib/plotstacked.R")      #!!!!!!!!!!!!!!!!!!!!!!!!!!
source("../lib/speechFuncs.R")         #contain funs
main.page <- read_html(x = "http://www.presidency.ucsb.edu/inaugurals.php")
inaug=f.speechlinks(main.page)
as.Date(inaug[,1], format="%B %e, %Y")
inaug=inaug[-nrow(inaug),] # remove the last line, irrelevant due to error.
inaug.list=read.csv("../data/InaugurationInfo.csv", stringsAsFactors = FALSE, header=TRUE, sep=";")
speech.list <- cbind(inaug.list, inaug$links)
colnames(speech.list)[6] <- "Dates"
filenames <- paste(speech.list$File, speech.list$Term, sep="-")
filenames <- paste("inaug",filenames,".txt", sep="")
speech.list$fulltext=NA
for(i in seq(nrow(speech.list))){
speech<-paste(readLines(paste("../data/InauguralSpeeches/",filenames[i],sep = ""), n=-1, skipNul=TRUE))
speech.list$fulltext[i]<-speech
}
colnames(speech.list)[7] <- "Fulltext"
View(speech.list)
speech.list$Fulltext[58]
speech.list$Fulltext[1]
nchar(speech.list$Fulltext[1])
nchar(speech.list$Fulltext[57])
nchar(speech.list$Fulltext[19])
substring(speech.list$Fulltext[19],20900,20974)
nchar(speech.list$Fulltext)
speech<-paste(readLines(paste("../data/InauguralSpeeches/",filenames[58],sep = ""), n=-1, skipNul=TRUE))
speech
filenames[58]
paste(speech, sep = " ")
cat(speech)
?cat
speech<-paste(readLines(paste("../data/InauguralSpeeches/",filenames[58],sep = ""), n=-1, skipNul=TRUE))
speech.list$Fulltext[58] <- cat(speech)
paste(speech, collapse = " ")
paste(speech, collapse = "")
speech.list$Fulltext[58] <- paste(speech, collapse = " ")
paste(speech, collapse
)
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# load packages
library("rvest")
library("tibble")
library("qdap")   # a lot of utility for text mining
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
source("../lib/plotstacked.R")      #!!!!!!!!!!!!!!!!!!!!!!!!!!
source("../lib/speechFuncs.R")         #contain funs
print(R.version)       #~for reproducibility
### Inauguaral speeches
main.page <- read_html(x = "http://www.presidency.ucsb.edu/inaugurals.php")
# Get link URLs
# f.speechlinks is a function for extracting links from the list of speeches.
inaug=f.speechlinks(main.page)
#head(inaug)
as.Date(inaug[,1], format="%B %e, %Y")
inaug=inaug[-nrow(inaug),] # remove the last line, irrelevant due to error.
inaug.list=read.csv("../data/InaugurationInfo.csv", stringsAsFactors = FALSE, header=TRUE, sep=";")
speech.list <- cbind(inaug.list, inaug$links)
colnames(speech.list)[6] <- "Dates"
#folder.path="../data/InauguralSpeeches/"
#speeches=list.files(path = folder.path, pattern = "*.txt")
filenames <- paste(speech.list$File, speech.list$Term, sep="-")
filenames <- paste("inaug",filenames,".txt", sep="")
speech.list$fulltext=NA
for(i in seq(nrow(speech.list))){
speech<-paste(readLines(paste("../data/InauguralSpeeches/",filenames[i],sep = ""), n=-1, skipNul=TRUE))
speech.list$fulltext[i]<-speech
}
colnames(speech.list)[7] <- "Fulltext"
speech<-paste(readLines(paste("../data/InauguralSpeeches/",filenames[58],sep = ""), n=-1, skipNul=TRUE))
speech.list$Fulltext[58] <- paste(speech, collapse = " ")
View(speech.list)
word_count(speech.list$Fulltext[1])
word_count(speech.list$Fulltext[58])
speech.list$Words[58] <- word_count(speech.list$Fulltext[58])
View(speech.list)
word_count(speech.list$Fulltext[2])
word_count(speech.list$Fulltext[3])
speech.list$Words <- NULL
View(speech.list)
nrow(speech.list)
sentences=sent_detect(speech.list$fulltext[1],
endmarks = c("?", ".", "!", "|",";"))
setences
sentences
sentences=sent_detect(speech.list$Fulltext[1],
endmarks = c("?", ".", "!", "|",";"))
sentences
sentences=sent_detect(speech.list$Fulltext[58],
endmarks = c("?", ".", "!", "|",";"))
sentences
sentences=sent_detect(speech.list$Fulltext[1],
endmarks = c("?", ".", "!", "|",";"))
emotions=get_nrc_sentiment(sentences)
emotions
emo <- emotions
emotions=diag(1/(word.count+0.01))%*%as.matrix(emotions)  #~get the emotion value for word in average
word.count=word_count(sentences)   #~ from qdap
emotions=diag(1/(word.count+0.01))%*%as.matrix(emotions)  #~get the emotion value for word in average
emotions
sentences
as.character(sentences)
sentence.list=rbind(sentence.list,
cbind(speech.list[i,-ncol(speech.list)],
sentences=as.character(sentences),
word.count,
emotions,
sent.id=1:length(sentences)
)
)
sentence.list=NULL
sentence.list=rbind(sentence.list,
cbind(speech.list[i,-ncol(speech.list)],
sentences=as.character(sentences),
word.count,
emotions,
sent.id=1:length(sentences)
)
)
View(sentence.list)
sentence.list=NULL
for(i in 1:nrow(speech.list)){
sentences=sent_detect(speech.list$Fulltext[i],
endmarks = c("?", ".", "!", "|",";"))
if(length(sentences)>0){
emotions=get_nrc_sentiment(sentences)
word.count=word_count(sentences)   #~ from qdap
# colnames(emotions)=paste0("emo.", colnames(emotions))
# in case the word counts are zeros?
emotions=diag(1/(word.count+0.01))%*%as.matrix(emotions)  #~get the emotion value for word in average
sentence.list=rbind(sentence.list,
cbind(speech.list[i,-ncol(speech.list)],
sentences=as.character(sentences),
word.count,
emotions,
sent.id=1:length(sentences)
)
)
}
}
sentence.list=
sentence.list%>%
filter(!is.na(word.count))
View(sentence.list)
sum(setence.list$negative > sentence.list$positive)
sum(sentence.list$negative > sentence.list$positive)
?summarise
collections<-group_by(setence.list, File, Term)
collections<-group_by(sentence.list, File, Term)
collections
ifelse(sentence.list$positive>=sentence.list$negative,1,0)
sentence.list$post1<- ifelse(sentence.list$positive>=sentence.list$negative,1,0) # if positive  negative, then 1. O.W :0
colnames(sentence.list)[ncol(sentence.list)] <- "PostOne"
View(sentence.list)
collections<-group_by(sentence.list, File, Term)
summarise(collections, positive_rate = mean(PostOne, na.rm = TRUE))
filter(sentence.list, File=="AbrahamLincoln", Term == 1)
filter(sentence.list, File=="AbrahamLincoln", Term == 1) %>% select(positive_rate)
filter(sentence.list, File=="AbrahamLincoln", Term == 1) %>% select(PostOne)
filter(sentence.list, File=="AbrahamLincoln", Term == 1) %>% select(PostOne)%>%mean()
filter(sentence.list, File=="AbrahamLincoln", Term == 1) %>% select(PostOne)%>%as.numeric()
filter(sentence.list, File=="AbrahamLincoln", Term == 1) %>% select(PostOne)
v<-filter(sentence.list, File=="AbrahamLincoln", Term == 1) %>% select(PostOne)
v
mean(v)
class(v)
mean(v$PostOne)
(PositiveTable <- summarise(collections, positive_rate = mean(PostOne, na.rm = TRUE)))
PositiveTable
arrange(PositiveTable, desc(positive_rate))
arrange(PositiveTable, positive_rate)
summarise(collections, positive_rate = mean(PostOne, na.rm = TRUE) %>% arrange(, positive_rate)
summarise(collections, positive_rate = mean(PostOne, na.rm = TRUE) %>% arrange(, positive_rate)
summarise(collections, positive_rate = mean(PostOne, na.rm = TRUE) %>% arrange(positive_rate)
summarise(collections, positive_rate = mean(PostOne, na.rm = TRUE)) %>% arrange(positive_rate)
summarise(collections, positive_rate = mean(PostOne, na.rm = TRUE))
summarise(collections, positive_rate = mean(PostOne, na.rm = TRUE)) %>% arrange(positive_rate)
library("rvest")
library("tibble")
library("qdap")   # a lot of utility for text mining
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("topicmodels")
library("wordcloud")
library("RColorBrewer")
library("tydytext")
source("../lib/plotstacked.R")      #!!!!!!!!!!!!!!!!!!!!!!!!!!
source("../lib/speechFuncs.R")         #contain funs
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels",
"wordcloud", "RColorBrewer",
"tydytext"
)
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library("rvest")
source("../lib/plotstacked.R")      #!!!!!!!!!!!!!!!!!!!!!!!!!!
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels",
"wordcloud", "RColorBrewer",
"tydytext"
)
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels",
"wordcloud", "RColorBrewer",
"tidytext"
)
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library("rvest")
library("tibble")
library("qdap")   # a lot of utility for text mining
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("topicmodels")
library("wordcloud")
library("RColorBrewer")
library("tidytext")
library("tidytext")
source("../lib/plotstacked.R")      #!!!!!!!!!!!!!!!!!!!!!!!!!!
source("../lib/speechFuncs.R")         #contain funs
folder.path="../data/inaugurals/"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)
prex.out
folder.path="../data/InauguralSpeeches/"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)
prex.out
ff.all<-Corpus(DirSource(folder.path))
packages.used=c("tm", "wordcloud", "RColorBrewer",
"dplyr", "tidytext")
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
folder.path="../data/inaugurals/"
speeches=list.files(path = folder.path, pattern = "*.txt")
folder.path="../data/InauguralSpeeches/"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)
prex.out
ff.all<-Corpus(DirSource(folder.path))
ff.all<-tm_map(ff.all, stripWhitespace)
ff.all<-tm_map(ff.all, content_transformer(tolower))
ff.all<-tm_map(ff.all, removeWords, stopwords("english"))
ff.all<-tm_map(ff.all, removeWords, character(0))  # null characters
ff.all<-tm_map(ff.all, removePunctuation)
tdm.all<-TermDocumentMatrix(ff.all)  #~ show how many time each words appear in each speech
View(tdm.all)
inspect(tdm.all)
tdm.tidy=tidy(tdm.all)  #~tidy function
View(tdm.tidy)
wordcloud(tdm.overall$term, tdm.overall$`sum(count)`,
scale=c(5,0.5),
max.words=100,
min.freq=1,
random.order=FALSE,
rot.per=0.3,
use.r.layout=T,
random.color=FALSE,
colors=brewer.pal(9,"Blues"))
tdm.overall=summarise(group_by(tdm.tidy, term), sum(count))
tdm.overall=summarise(group_by(tdm.tidy, term), sum(count))
wordcloud(tdm.overall$term, tdm.overall$`sum(count)`,
scale=c(5,0.5),
max.words=100,
min.freq=1,
random.order=FALSE,
rot.per=0.3,
use.r.layout=T,
random.color=FALSE,
colors=brewer.pal(9,"Blues"))
wordcloud(tdm.overall$term, tdm.overall$`sum(count)`,
scale=c(5,0.5),
max.words=100,
min.freq=1,
random.order=FALSE,
rot.per=0.3,
use.r.layout=T,
random.color=FALSE,
colors=brewer.pal(9,"Blues"))
dtm <- DocumentTermMatrix(ff.all,
control = list(weighting = function(x)
weightTfIdf(x,
normalize =FALSE),
stopwords = TRUE))
ff.dtm=tidy(dtm)
View(ff.dtm)
(tables <- summarise(collections, positive_rate = mean(PostOne, na.rm = TRUE)) %>% arrange(positive_rate))
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels",
"wordcloud", "RColorBrewer",
"tidytext"
)
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library("rvest")
library("tibble")
library("qdap")   # a lot of utility for text mining
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("topicmodels")
library("wordcloud")
library("RColorBrewer")
library("tidytext")
source("../lib/plotstacked.R")      #!!!!!!!!!!!!!!!!!!!!!!!!!!
source("../lib/speechFuncs.R")         #contain funs
main.page <- read_html(x = "http://www.presidency.ucsb.edu/inaugurals.php")
main.page <- read_html(x = "http://www.presidency.ucsb.edu/inaugurals.php")
main.page <- read_html(x = "http://www.presidency.ucsb.edu/inaugurals.php")
main.page <- read_html(x = "http://www.presidency.ucsb.edu/inaugurals.php")
inaug=f.speechlinks(main.page)
inaug=inaug[-nrow(inaug),] # remove the last line, irrelevant due to error.
inaug.list=read.csv("../data/InaugurationInfo.csv", stringsAsFactors = FALSE, header=TRUE, sep=";")
speech.list <- cbind(inaug.list, inaug$links)
colnames(speech.list)[6] <- "Dates"
filenames <- paste(speech.list$File, speech.list$Term, sep="-")
filenames <- paste("inaug",filenames,".txt", sep="")
speech.list$fulltext=NA
for(i in seq(nrow(speech.list))){
speech<-paste(readLines(paste("../data/InauguralSpeeches/",filenames[i],sep = ""), n=-1, skipNul=TRUE))
speech.list$fulltext[i]<-speech
}
colnames(speech.list)[7] <- "Fulltext"
speech<-paste(readLines(paste("../data/InauguralSpeeches/",filenames[58],sep = ""), n=-1, skipNul=TRUE))
speech.list$Fulltext[58] <- paste(speech, collapse = " ")
speech.list$Words <- NULL
sentence.list=NULL
for(i in 1:nrow(speech.list)){
sentences=sent_detect(speech.list$Fulltext[i],
endmarks = c("?", ".", "!", "|",";"))
if(length(sentences)>0){
emotions=get_nrc_sentiment(sentences)
word.count=word_count(sentences)   #~ from qdap
# colnames(emotions)=paste0("emo.", colnames(emotions))
# in case the word counts are zeros?
emotions=diag(1/(word.count+0.01))%*%as.matrix(emotions)  #~get the emotion value for word in average
sentence.list=rbind(sentence.list,
cbind(speech.list[i,-ncol(speech.list)],
sentences=as.character(sentences),
word.count,
emotions,
sent.id=1:length(sentences)
)
)
}
}
sentence.list=
sentence.list%>%
filter(!is.na(word.count))
sentence.list$post1<- ifelse(sentence.list$positive>=sentence.list$negative,1,0) # if positive  negative, then 1. O.W :0
colnames(sentence.list)[ncol(sentence.list)] <- "PostOne"
collections<-group_by(sentence.list, File, Term)()
collections<-group_by(sentence.list, File, Term)
(tables <- summarise(collections, positive_rate = mean(PostOne, na.rm = TRUE)) %>% arrange(positive_rate))
folder.path="../data/InauguralSpeeches/"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)
ff.all<-Corpus(DirSource(folder.path))
ff.all<-tm_map(ff.all, stripWhitespace) %>% tm_map(content_transformer(tolower)) %>% tm_map(removeWords, stopwords("english")) %>% tm_map(removeWords, character(0)) %>%  tm_map(removePunctuation)
top_n(tables,10)
top_n(tables,10)
folder.path="../data/InauguralSpeeches/"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)
ff.all<-Corpus(DirSource(folder.path))
ff.all<-tm_map(ff.all, stripWhitespace) %>% tm_map(content_transformer(tolower)) %>% tm_map(removeWords, stopwords("english")) %>% tm_map(removeWords, character(0)) %>%  tm_map(removePunctuation)
dtm <- DocumentTermMatrix(ff.all,
control = list(weighting = function(x)
weightTfIdf(x,
normalize =FALSE),
stopwords = TRUE))
ff.dtm=tidy(dtm)
View(ff.dtm)
as.data.frame(tables)
class(as.data.frame(tables))
?slice
slice(tables, 1:10)
select(tables, File, Term)
as.data.frame(select(tables, File, Term))[1:10,]
apply( as.data.frame(select(tables, File, Term))[1:10,] , 1 , paste , collapse = "-" )
names <- apply( as.data.frame(select(tables, File, Term))[1:10,] , 1 , paste , collapse = "-" )
names
names <- as.character(apply( as.data.frame(select(tables, File, Term))[1:10,] , 1 , paste , collapse = "-" ))
names
inaugAbrahamLincoln-1.txt
names <- paste("inaug", names, ".txt", sep="")
names
?png
getwd()
names1 <- as.character(apply( as.data.frame(select(tables, File, Term))[1:10,] , 1 , paste , collapse = "-" ))
names <- paste("inaug", names1, ".txt", sep="")
names1
ff.dtm$document == names[1]
for(i in 1:10){
png(paste(names1[i],".png", sep=""), width=6, height=6, units="in", res=300)
terms<-ff.dtm$term[ff.dtm$document == names[i]]
counts<-ff.dtm$count[ff.dtm$document == names[i]]
wordcloud(terms, counts,
scale=c(5,0.5),
max.words=100,
min.freq=1,
random.order=FALSE,
rot.per=0.3,
use.r.layout=T,
random.color=FALSE,
colors=brewer.pal(9,"Blues"))
dev.off()
}
